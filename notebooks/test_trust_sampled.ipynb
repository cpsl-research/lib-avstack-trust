{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db8646c4-a0dd-49c9-a478-821d8e1b3630",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mate\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import deepcopy\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "\n",
    "seed = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a599d1-27ed-4c41-84b3-023840bf249b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kld(p: np.ndarray, q: np.ndarray, EPS: float = np.finfo(float).eps) -> float:\n",
    "    p += EPS\n",
    "    q += EPS\n",
    "    p /= sum(p)\n",
    "    q /= sum(q)\n",
    "    idx_keep = (p > 0) & (q > 0) & (~np.isnan(p)) & (~np.isnan(q))\n",
    "    p = p[idx_keep]\n",
    "    q = q[idx_keep]\n",
    "    return sum(p * np.log2(p / q))\n",
    "\n",
    "\n",
    "def evaluate(output, log_interval):\n",
    "    def f(x):\n",
    "        idx = x // log_interval\n",
    "        return evaluate_single(output[\"dists\"][idx], output[\"estimators\"][idx])\n",
    "    n_steps = (len(output[\"dists\"])-1) * log_interval\n",
    "    interact(f, x=widgets.IntSlider(min=0, max=n_steps, step=log_interval, value=n_steps))\n",
    "\n",
    "\n",
    "def evaluate_single(dists, estimators, figsize=(20,5), linewidth=2.5, eps=1e-3):\n",
    "    # -- difference in means/variance\n",
    "    IDs = list(range(len(dists)))\n",
    "    mn_true = {ID: dist.mean for ID, dist in zip(IDs, dists)}\n",
    "    var_true = {ID: dist.variance for ID, dist in zip(IDs, dists)}\n",
    "    mn_ests = [{ID: est.mean(ID=ID) for ID in IDs} for est in estimators]\n",
    "    # var_ests = [{ID: est.variance(ID=ID) for ID in IDs} for est in estimators]\n",
    "    \n",
    "    # -- KLD of full distributions\n",
    "    n_samples = 10000\n",
    "    x_test = np.linspace(eps, 1-eps, num=n_samples)\n",
    "    q_true = {ID: dist.pdf(x_test) for ID, dist in zip(IDs, dists)}\n",
    "    p_ests = [{ID: est.pdf(x_test, ID=ID) for ID in IDs} for est in estimators]\n",
    "    kld_ests = [{ID: kld(p_est[ID], q_true[ID]) for ID in IDs} for p_est in p_ests]\n",
    "    \n",
    "    # -- plot results\n",
    "    maxys = []\n",
    "    fig, axs = plt.subplots(nrows=1, ncols=len(dists), figsize=figsize, sharey=True)\n",
    "    for j in range(len(dists)):\n",
    "        axs[j].plot(x_test, q_true[j], linewidth=linewidth, label=\"True Distribution\")\n",
    "        axs[j].fill_between(x_test, q_true[j], alpha=0.5)\n",
    "        axs[j].set_title(\"Agent {}\".format(j))\n",
    "        maxys.append(max(q_true[j]))\n",
    "        for i, est in enumerate(estimators):\n",
    "            axs[j].plot(x_test, p_ests[i][j], linewidth=linewidth, label=est.name)\n",
    "            \n",
    "    # -- set y lim\n",
    "    axs[0].set_ylim(0, 1.2*np.mean(maxys))\n",
    "    axs[0].get_yaxis().set_ticklabels([])\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff840df",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPS = 1e-8\n",
    "\n",
    "class TrustSampler:\n",
    "    def __init__(\n",
    "        self,\n",
    "        temporal_correlation=None,\n",
    "        spatial_correlation=None,\n",
    "        platform_correlation=None,\n",
    "    ):\n",
    "        self.c_temporal = temporal_correlation\n",
    "        self.c_spatial = spatial_correlation\n",
    "        self.c_platfom = platform_correlation\n",
    "        self._last_trust = None\n",
    "\n",
    "    def sample(self, agents, dists, noise_strength=0.05):\n",
    "        ID = np.array([agent.ID for agent in agents])\n",
    "        trust_vs =  np.array([dist.rvs(n=1)[0] for dist in dists])\n",
    "        \n",
    "        # apply temporal correlations\n",
    "        if self.c_temporal:\n",
    "            if self._last_trust is not None:\n",
    "                white_noise = noise_strength * np.random.randn(len(dists))\n",
    "                trust_vs = (trust_vs + self.c_temporal * self._last_trust) / (1+self.c_temporal) + white_noise\n",
    "\n",
    "        # apply spatial correlations\n",
    "        if self.c_spatial:\n",
    "            raise\n",
    "\n",
    "        # apply platform correlations\n",
    "        if self.c_platfom:\n",
    "            raise\n",
    "        \n",
    "        # store for later\n",
    "        trust_vs = np.clip(trust_vs, 0.0+EPS, 1.0-EPS)\n",
    "        self._last_trust = trust_vs\n",
    "\n",
    "        trusts = mate.measurement.TrustArray(trust=trust_vs, ID=ID)\n",
    "        return trusts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f4d1d75-e019-4432-85b7-0af8af539441",
   "metadata": {},
   "source": [
    "## 1. Uncorrelated Stationary\n",
    "\n",
    "The trust of each agent is provided as a sample from an underlying Beta distribution per agent. There are no correlations - each measurement is independent and each agent is independent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7ec74c-df8a-4ef5-9d80-9d864640d1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_beta_agents(n_agents=8, t_prior=0.5):\n",
    "    agents = [\n",
    "        mate.state.Agent(\n",
    "            ID=i,\n",
    "            pose=None,\n",
    "            fov=None,\n",
    "            trust_prior=t_prior\n",
    "        ) for i in range(n_agents)\n",
    "    ]\n",
    "    distributions = [\n",
    "        mate.distribution.Beta(\n",
    "            alpha=np.random.randint(low=1, high=10),\n",
    "            beta=np.random.randint(low=1, high=10)\n",
    "        ) for _ in range(n_agents)\n",
    "    ]\n",
    "    return agents, distributions\n",
    "\n",
    "\n",
    "def init_estimators(agents, t0=0.0):\n",
    "    estimators = [\n",
    "        mate.estimate.MultiTrustEstimatorWrapper(\n",
    "            t0=t0,\n",
    "            estimator_base=mate.estimate.VotingTrustEstimator,\n",
    "            p0=0.5,\n",
    "            time_window=None\n",
    "        ),\n",
    "        mate.estimate.MultiTrustEstimatorWrapper(\n",
    "            t0=t0,\n",
    "            estimator_base=mate.estimate.MaximumLikelihoodTrustEstimator,\n",
    "            distribution={\"type\": \"Beta\", \"alpha\": 1.0, \"beta\": 1.0},\n",
    "            update_rate=1,\n",
    "            time_window=30,\n",
    "            forgetting=0.10,\n",
    "            max_variance=None,\n",
    "\n",
    "        ),\n",
    "        mate.estimate.DirectLinearKalmanTrustEstimator(\n",
    "            t0=t0,\n",
    "            process_noise=0.20,\n",
    "        )\n",
    "    ]\n",
    "    for est in estimators:\n",
    "        for agent in agents:\n",
    "            est.add_agent(ID=agent.ID)\n",
    "    return estimators"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "262bd099-6ec4-4b04-b2b4-7b1aa57910b1",
   "metadata": {},
   "source": [
    "### 1.1 No confidence provided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d29e80a-1323-4191-9985-1eec9a10c04e",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_interval = 10\n",
    "\n",
    "# initialize distributions/estimators\n",
    "np.random.seed(seed)\n",
    "agents, dists = init_beta_agents()\n",
    "estimators = init_estimators(agents)\n",
    "sampler = TrustSampler(temporal_correlation=1.0)\n",
    "dt = 1.0\n",
    "n_steps = 100\n",
    "\n",
    "# run trust estimation\n",
    "output = {\"dists\": [deepcopy(dists)], \"estimators\": [deepcopy(estimators)]}\n",
    "trusts_all = []\n",
    "for i in range(n_steps):\n",
    "    t = dt * i\n",
    "    trusts = sampler.sample(agents=agents, dists=dists, noise_strength=0.01)\n",
    "    trusts_all.append(trusts)\n",
    "    for est in estimators:\n",
    "        est.update(timestamp=t, trust=trusts)\n",
    "    if (i+1) % log_interval == 0:\n",
    "        output[\"dists\"].append(dists)\n",
    "        output[\"estimators\"].append(deepcopy(estimators))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5a7c85-222c-4d4b-a521-e83335ba9e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(output, log_interval)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa95870-32b1-4a17-9e0b-5adf4b0e317b",
   "metadata": {},
   "source": [
    "### 1.2 Confidence provided\n",
    "\n",
    "Confidence generated as related to the deviation of the underlying Beta distribution with some noise added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c055ed29-fe89-407d-9974-b457e0f90c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cfunc(tr, dist):\n",
    "    return 1 - abs(tr-dist.mean)**(1/2)\n",
    "    \n",
    "# initialize distributions/estimators\n",
    "log_interval = 10\n",
    "np.random.seed(seed)\n",
    "agents, dists = init_beta_agents()\n",
    "estimators = init_estimators(agents)\n",
    "\n",
    "dt = 1.0\n",
    "n_steps = 100\n",
    "\n",
    "# run trust estimation\n",
    "ID = np.array([agent.ID for agent in agents])\n",
    "output = {\"dists\": [deepcopy(dists)], \"estimators\": [deepcopy(estimators)]}\n",
    "for i in range(n_steps):\n",
    "    t = dt * i\n",
    "    trust = np.array([dist.rvs(n=1)[0] for dist in dists])\n",
    "    confidence = np.asarray([cfunc(tr, dist) for tr, dist in zip(trust, dists)])\n",
    "    prior = 0.5 * np.ones((len(agents),))\n",
    "    trusts = mate.measurement.UncertainTrustArray(trust=trust, confidence=confidence, prior=prior, ID=ID)\n",
    "    for est in estimators:\n",
    "        est.update(timestamp=t, trust=trusts)\n",
    "    if (i+1) % log_interval == 0:\n",
    "        output[\"dists\"].append(dists)\n",
    "        output[\"estimators\"].append(deepcopy(estimators))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa2f8d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(output, log_interval)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "068891c7-3f1e-4db5-bf02-3f854a3c5cd8",
   "metadata": {},
   "source": [
    "## 2. Uncorrelated with Smooth Dynamics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "726c934e-3fe3-4a0f-9b1c-95edbf6a7c8c",
   "metadata": {},
   "source": [
    "### 1.1 No confidence provided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "351e3eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "\n",
    "\n",
    "class MovingDistribution:\n",
    "    def __init__(self, weight: float, dist_0, dist_1):\n",
    "        mn = (1-weight)*dist_0.mean + weight*dist_1.mean\n",
    "        var = ((1-weight)*np.sqrt(dist_0.variance) + weight*np.sqrt(dist_1.variance))**2\n",
    "        self.dist = type(dist_0)(mean=mn, var=var)\n",
    "\n",
    "    def mean(self):\n",
    "        return self.dist.mean\n",
    "    \n",
    "    def variance(self):\n",
    "        return self.dist.variance\n",
    "    \n",
    "    def rvs(self, n: int):\n",
    "        return self.dist.rvs(n=n)\n",
    "    \n",
    "    def pdf(self, x):\n",
    "        return self.dist.pdf(x=x)\n",
    "\n",
    "\n",
    "class DistributionSum:\n",
    "    def __init__(self, weight: float, dist_0, dist_1):\n",
    "        self.weight = weight\n",
    "        self.dist_0 = dist_0\n",
    "        self.dist_1 = dist_1\n",
    "        \n",
    "    def mean(self):\n",
    "        return (1-self.weight)*self.dist_0.mean + \\\n",
    "            self.weight*self.dist_1.mean\n",
    "    \n",
    "    def variance(self):\n",
    "        raise NotImplementedError        \n",
    "\n",
    "    def rvs(self, n: int):\n",
    "        return (1-self.weight)*self.dist_0.rvs(n=n) + \\\n",
    "            self.weight*self.dist_1.rvs(n=n)\n",
    "    \n",
    "    def pdf(self, x):\n",
    "        return (1-self.weight)*self.dist_0.pdf(x=x) + \\\n",
    "            self.weight*self.dist_1.pdf(x=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da84897",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize distributions/estimators\n",
    "log_interval = 10\n",
    "np.random.seed(seed)\n",
    "agents, dists_0 = init_beta_agents()\n",
    "_, dists_1 = init_beta_agents()\n",
    "estimators = init_estimators(agents)\n",
    "\n",
    "dt = 1.0\n",
    "n_steps = 100\n",
    "\n",
    "# run trust estimation\n",
    "ID = np.array([agent.ID for agent in agents])\n",
    "dists = [MovingDistribution(weight=0.0, dist_0=dist_0, dist_1=dist_1) for dist_0, dist_1 in zip(dists_0, dists_1)]\n",
    "output = {\"dists\": [deepcopy(dists)], \"estimators\": [deepcopy(estimators)]}\n",
    "for i in range(n_steps):\n",
    "    w = i / (n_steps-1)\n",
    "    t = dt * i\n",
    "    dists = [MovingDistribution(weight=w, dist_0=dist_0, dist_1=dist_1) for dist_0, dist_1 in zip(dists_0, dists_1)]\n",
    "    trust = np.array([dist.rvs(n=1)[0] for dist in dists])\n",
    "    trusts = mate.measurement.TrustArray(trust=trust, ID=ID)\n",
    "    for est in estimators:\n",
    "        est.update(timestamp=t, trust=trusts)\n",
    "    if (i+1) % log_interval == 0:\n",
    "        output[\"dists\"].append(dists)\n",
    "        output[\"estimators\"].append(deepcopy(estimators))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61e8f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(output, log_interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc74a3ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mate-anjulgyC-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "47e93aaed00cdf9cc1559b6ae09069cd8788ce5bd0fbfe97e48a970742fcf35b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
